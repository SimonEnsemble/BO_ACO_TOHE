# note: combined heuristic could be reward per survival probability?
Ïµ = 0.05 # small number to add, to avoid it being zero...
"""
    Î·_r(u, v, top)
    Î·_r(u, v, top, previous_robots)

heuristic score for a hop u -> v, concerning objective ð”¼[reward].

## method 1: doesn't consider previous robots' paths
score = ð”¼[reward of node v] / (max reward among all nodes)
normalized so âˆˆ [0, 1], for comparison with Î·_s

## method 2: considers previous robots' paths.
a sequential perspective.
score = ð”¼[reward of node v | previous robots already deployed] / (max reward among all nodes)
this robot can only get the reward if none of the previous robots successfully visit this node.
"""
function Î·_r(u::Int, v::Int, top::TOP)
    return Ïµ + get_Ï‰(top, u, v) * get_r(top, v)
end

function Î·_r(u::Int, v::Int, top::TOP, previous_robots::Vector{Robot})
    # only get expected one-hop reward if none of the previous robots visisted.
    # special case if v = 1. then we don't use this rule, since it would never be selected.
    if v == 1
        return Î·_r(u, v, top)
    else
        return Ïµ + Î·_r(u, v, top) * (1.0 - Ï€_some_robot_visits_node_j(previous_robots, v, top))
    end
end

"""
    Î·_s(u, v, top)

heuristic score for a hop u -> v, concerning objective ð”¼[# robots survive].
score = prob. of surviving that edge.

note: if 1 -> 1 hop, survival prob is 1.0
"""
function Î·_s(u::Int, v::Int, top::TOP)
    Ïµ = 0.01 # to avoid it being zero...
	if u == v == 1 # gonna survive fo sho if we stay at base
		return 1.0 + Ïµ
	end
    return Ïµ + get_Ï‰(top, u, v)
end
